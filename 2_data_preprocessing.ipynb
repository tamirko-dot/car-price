{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ”§ ×©×œ×‘ 2: ×¢×™×‘×•×“ × ×ª×•× ×™× ×•×”×›× ×” ×œ××•×“×œ (Data Preprocessing)\n",
    "\n",
    "## ××˜×¨×”\n",
    "×‘×©×œ×‘ ×–×” × ×›×™×Ÿ ××ª ×”× ×ª×•× ×™× ×œ××•×“×œ Machine Learning:\n",
    "1. **×‘×“×™×§×ª ×¢×¨×›×™× ×—×¡×¨×™×** ×•×”×—×œ×¤×ª× ×‘×××•×¦×¢×™×\n",
    "2. **×§×™×“×•×“ ××©×ª× ×™× ×§×˜×’×•×¨×™××œ×™×™×** (Encoding)\n",
    "3. **×‘×—×™×¨×ª ××©×ª× ×™× ×¨×œ×•×•× ×˜×™×™×**\n",
    "4. **×–×™×”×•×™ ×•×”×¡×¨×ª ×¢×¨×›×™× ×§×™×¦×•× ×™×™×** (Outliers)\n",
    "5. **×”×¤×¨×“×ª X ×•-y**\n",
    "6. **×¤×™×¦×•×œ ×œ× ×ª×•× ×™ ××™××•×Ÿ ×•×‘×“×™×§×”** (80/20)\n",
    "7. **× ×•×¨××œ×™×–×¦×™×”** (StandardScaler)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ×™×™×‘×•× ×¡×¤×¨×™×•×ª\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ“ ×¡×¤×¨×™×•×ª × ×˜×¢× ×• ×‘×”×¦×œ×—×”\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ×˜×¢×™× ×ª ×”× ×ª×•× ×™×"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ×˜×¢×™× ×ª ×”× ×ª×•× ×™×\n",
    "df = pd.read_csv('lamborghini_sales_2020_2025.csv')\n",
    "df_ml = df.copy()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"× ×ª×•× ×™× ×œ××•×“×œ Machine Learning\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n××¡×¤×¨ ×¨×©×•××•×ª: {len(df_ml)}\")\n",
    "print(f\"××¡×¤×¨ ×¢××•×“×•×ª: {len(df_ml.columns)}\")\n",
    "print(f\"\\n×¢××•×“×•×ª: {list(df_ml.columns)}\")\n",
    "print(f\"\\n×¦×•×¨×ª ×”× ×ª×•× ×™×: {df_ml.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ×‘×“×™×§×ª ×¢×¨×›×™× ×—×¡×¨×™×\n",
    "\n",
    "**×œ××” ×–×” ×—×©×•×‘?**  \n",
    "×¢×¨×›×™× ×—×¡×¨×™× (Missing Values) ×™×›×•×œ×™× ×œ×’×¨×•× ×œ×©×’×™××•×ª ×‘××•×“×œ ××• ×œ×”×˜×•×ª ××ª ×”×ª×•×¦××•×ª.  \n",
    "×× ×™×© ×¢×¨×›×™× ×—×¡×¨×™×, × ×˜×¤×œ ×‘×”× ×œ×¤×™ ×¡×•×’ ×”×¢××•×“×”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ×‘×“×™×§×ª ×¢×¨×›×™× ×—×¡×¨×™×\n",
    "print(\"=\"*80)\n",
    "print(\"×‘×“×™×§×ª ×¢×¨×›×™× ×—×¡×¨×™× (Missing Values)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "missing_values = df_ml.isnull().sum()\n",
    "missing_percentage = (df_ml.isnull().sum() / len(df_ml)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Column': df_ml.columns,\n",
    "    'Missing Values': missing_values.values,\n",
    "    'Percentage': missing_percentage.values\n",
    "})\n",
    "\n",
    "print(missing_df)\n",
    "\n",
    "if df_ml.isnull().sum().sum() == 0:\n",
    "    print(\"\\nâœ“ ××™×Ÿ ×¢×¨×›×™× ×—×¡×¨×™× ×‘× ×ª×•× ×™×!\")\n",
    "else:\n",
    "    print(f\"\\nâš  × ××¦××• {df_ml.isnull().sum().sum()} ×¢×¨×›×™× ×—×¡×¨×™×\")\n",
    "    \n",
    "    # ××™×œ×•×™ ×¢×¨×›×™× ×—×¡×¨×™×\n",
    "    numeric_columns = df_ml.select_dtypes(include=[np.number]).columns\n",
    "    for col in numeric_columns:\n",
    "        if df_ml[col].isnull().sum() > 0:\n",
    "            mean_value = df_ml[col].mean()\n",
    "            df_ml[col].fillna(mean_value, inplace=True)\n",
    "            print(f\"  - {col}: ××•×œ××• ×‘×××•×¦×¢ ({mean_value:.2f})\")\n",
    "    \n",
    "    categorical_columns = df_ml.select_dtypes(include=['object']).columns\n",
    "    for col in categorical_columns:\n",
    "        if df_ml[col].isnull().sum() > 0:\n",
    "            mode_value = df_ml[col].mode()[0]\n",
    "            df_ml[col].fillna(mode_value, inplace=True)\n",
    "            print(f\"  - {col}: ××•×œ××• ×‘×¢×¨×š ×”× ×¤×•×¥ ({mode_value})\")\n",
    "\n",
    "print(f\"\\n×¡×”\\\"×› ×¢×¨×›×™× ×—×¡×¨×™× ××—×¨×™ ×˜×™×¤×•×œ: {df_ml.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ×§×™×“×•×“ ××©×ª× ×™× ×§×˜×’×•×¨×™××œ×™×™× (Encoding)\n",
    "\n",
    "**××” ×–×” ×§×™×“×•×“?**  \n",
    "××•×“×œ×™ Machine Learning ×¢×•×‘×“×™× ×¨×§ ×¢× ××¡×¤×¨×™×. ××©×ª× ×™× ×§×˜×’×•×¨×™××œ×™×™× (×˜×§×¡×˜) ×¦×¨×™×›×™× ×œ×”×¤×•×š ×œ××¡×¤×¨×™×.\n",
    "\n",
    "**×©×™×˜×•×ª:**\n",
    "- **Label Encoding**: ×”××¨×” ×œ×¢×¨×›×™× 0, 1, 2... (×œ××©×ª× ×™× ×‘×™× ××¨×™×™×)\n",
    "- **One-Hot Encoding**: ×™×¦×™×¨×ª ×¢××•×“×” × ×¤×¨×“×ª ×œ×›×œ ×§×˜×’×•×¨×™×” (×œ××©×ª× ×™× ×¨×‘-×§×˜×’×•×¨×™××œ×™×™×)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ×§×™×“×•×“ ××©×ª× ×™× ×§×˜×’×•×¨×™××œ×™×™×\n",
    "print(\"=\"*80)\n",
    "print(\"×§×™×“×•×“ ××©×ª× ×™× ×§×˜×’×•×¨×™××œ×™×™× (Encoding)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "categorical_cols = df_ml.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"\\n×¢××•×“×•×ª ×§×˜×’×•×¨×™××œ×™×•×ª: {categorical_cols}\\n\")\n",
    "\n",
    "encoding_info = {}\n",
    "\n",
    "# Label Encoding ×œ××©×ª× ×™× ×‘×™× ××¨×™×™×\n",
    "if 'Turbo (Yes/No)' in df_ml.columns:\n",
    "    le = LabelEncoder()\n",
    "    df_ml['Turbo_Encoded'] = le.fit_transform(df_ml['Turbo (Yes/No)'])\n",
    "    encoding_info['Turbo'] = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "    print(f\"âœ“ Turbo: {encoding_info['Turbo']}\")\n",
    "\n",
    "if 'Fuel Type' in df_ml.columns:\n",
    "    le = LabelEncoder()\n",
    "    df_ml['Fuel_Type_Encoded'] = le.fit_transform(df_ml['Fuel Type'])\n",
    "    encoding_info['Fuel Type'] = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "    print(f\"âœ“ Fuel Type: {encoding_info['Fuel Type']}\")\n",
    "\n",
    "# One-Hot Encoding ×œ××©×ª× ×™× ×¨×‘-×§×˜×’×•×¨×™××œ×™×™×\n",
    "onehot_cols = ['Model', 'Region', 'Color']\n",
    "\n",
    "for col in onehot_cols:\n",
    "    if col in df_ml.columns:\n",
    "        dummies = pd.get_dummies(df_ml[col], prefix=col, drop_first=True)\n",
    "        df_ml = pd.concat([df_ml, dummies], axis=1)\n",
    "        print(f\"âœ“ {col}: × ×•×¦×¨×• {len(dummies.columns)} ×¢××•×“×•×ª ×—×“×©×•×ª\")\n",
    "        encoding_info[col] = dummies.columns.tolist()\n",
    "\n",
    "print(f\"\\nâœ“ ×§×™×“×•×“ ×”×•×©×œ×! ×¢×›×©×™×• ×™×© {len(df_ml.columns)} ×¢××•×“×•×ª\")\n",
    "print(f\"×¦×•×¨×” ×—×“×©×”: {df_ml.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ×‘×—×™×¨×ª ××©×ª× ×™× ×¨×œ×•×•× ×˜×™×™×\n",
    "\n",
    "**××” × ×¢×©×” ×›××Ÿ?**\n",
    "- × ×¡×™×¨ ×¢××•×“×•×ª ×§×˜×’×•×¨×™××œ×™×•×ª ××§×•×¨×™×•×ª (×©×›×‘×¨ ×§×™×“×“× ×•)\n",
    "- × ×¡×™×¨ Sales Volume (×œ× ×¨×œ×•×•× ×˜×™ ×œ×—×™×–×•×™ ××—×™×¨)\n",
    "- × ×©××™×¨ ×¨×§ ××©×ª× ×™× ×©××©×¤×™×¢×™× ×¢×œ ×”××—×™×¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ×”×¡×¨×ª ×¢××•×“×•×ª ×œ× ×¨×œ×•×•× ×˜×™×•×ª\n",
    "print(\"=\"*80)\n",
    "print(\"×‘×—×™×¨×ª ××©×ª× ×™× ×¨×œ×•×•× ×˜×™×™× ×œ××•×“×œ\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "columns_to_drop = ['Model', 'Region', 'Color', 'Fuel Type', 'Turbo (Yes/No)', 'Sales Volume']\n",
    "df_ml_cleaned = df_ml.drop(columns=[col for col in columns_to_drop if col in df_ml.columns], errors='ignore')\n",
    "\n",
    "print(f\"\\nâœ“ ×”×•×¡×¨×• {len(columns_to_drop)} ×¢××•×“×•×ª\")\n",
    "print(f\"âœ“ × ×•×ª×¨×• {len(df_ml_cleaned.columns)} ×¢××•×“×•×ª\\n\")\n",
    "\n",
    "print(\"×¢××•×“×•×ª ×©× ×©××¨×•:\")\n",
    "print(\"-\" * 40)\n",
    "for i, col in enumerate(df_ml_cleaned.columns, 1):\n",
    "    print(f\"{i:2}. {col}\")\n",
    "\n",
    "if 'Base Price (USD)' in df_ml_cleaned.columns:\n",
    "    print(\"\\nâœ“ ×¢××•×“×ª ×”××—×™×¨ (Target) ×§×™×™××ª\")\n",
    "\n",
    "print(f\"\\n×¦×•×¨×” ×¡×•×¤×™×ª: {df_ml_cleaned.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ×–×™×”×•×™ Outliers (×¢×¨×›×™× ×§×™×¦×•× ×™×™×)\n",
    "\n",
    "**××” ×–×” Outliers?**  \n",
    "×¢×¨×›×™× ×—×¨×™×’×™× ×©×™×›×•×œ×™× ×œ×©×‘×© ××ª ×”××•×“×œ.\n",
    "\n",
    "**×©×™×˜×ª IQR:**\n",
    "- Q1 = ×¨×‘×¢×•×Ÿ ×ª×—×ª×•×Ÿ (25%)\n",
    "- Q3 = ×¨×‘×¢×•×Ÿ ×¢×œ×™×•×Ÿ (75%)\n",
    "- IQR = Q3 - Q1\n",
    "- ×¢×¨×›×™× ××—×•×¥ ×œ-[Q1-1.5Ã—IQR, Q3+1.5Ã—IQR] = outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ×–×™×”×•×™ Outliers\n",
    "print(\"=\"*80)\n",
    "print(\"×–×™×”×•×™ ×¢×¨×›×™× ×§×™×¦×•× ×™×™× (Outliers)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "numeric_cols_for_outliers = ['Base Price (USD)', 'Horsepower', 'Year']\n",
    "outliers_found = {}\n",
    "\n",
    "fig, axes = plt.subplots(1, len(numeric_cols_for_outliers), figsize=(16, 5))\n",
    "\n",
    "for idx, col in enumerate(numeric_cols_for_outliers):\n",
    "    if col in df_ml_cleaned.columns:\n",
    "        Q1 = df_ml_cleaned[col].quantile(0.25)\n",
    "        Q3 = df_ml_cleaned[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        outliers = df_ml_cleaned[(df_ml_cleaned[col] < lower_bound) | (df_ml_cleaned[col] > upper_bound)]\n",
    "        outliers_found[col] = len(outliers)\n",
    "        \n",
    "        axes[idx].boxplot(df_ml_cleaned[col], vert=True)\n",
    "        axes[idx].set_title(f'{col}\\n({outliers_found[col]} outliers)', fontweight='bold')\n",
    "        axes[idx].set_ylabel('Value')\n",
    "        axes[idx].grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        print(f\"\\n{col}:\")\n",
    "        print(f\"  Q1: {Q1:,.2f}, Q3: {Q3:,.2f}, IQR: {IQR:,.2f}\")\n",
    "        print(f\"  Outliers: {outliers_found[col]}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"×”×—×œ×˜×”: Outliers ×”× ×œ×’×™×˜×™××™×™× (×“×’××™ ×™×•×§×¨×”) - ×œ× × ×¡×™×¨ ××•×ª×\")\n",
    "print(f\"×¡×”\\\"×› ×©×•×¨×•×ª: {len(df_ml_cleaned)}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ×”×¤×¨×“×ª X ×•-y\n",
    "\n",
    "**X (Features)**: ×”××©×ª× ×™× ×”×‘×œ×ª×™ ×ª×œ×•×™×™× - ××”× × ×—×–×”  \n",
    "**y (Target)**: ×”××©×ª× ×” ×”×ª×œ×•×™ - ××” ×©×× ×—× ×• ×¨×•×¦×™× ×œ×—×–×•×ª (×”××—×™×¨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ×”×¤×¨×“×ª X ×•-y\n",
    "print(\"=\"*80)\n",
    "print(\"×”×¤×¨×“×ª ××©×ª× ×™×: X (Features) ×•-y (Target)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if 'Base Price (USD)' not in df_ml_cleaned.columns:\n",
    "    print(\"âš  ×©×’×™××”: ×¢××•×“×ª ×”××—×™×¨ ×œ× × ××¦××”!\")\n",
    "else:\n",
    "    y = df_ml_cleaned['Base Price (USD)']\n",
    "    X = df_ml_cleaned.drop('Base Price (USD)', axis=1)\n",
    "    \n",
    "    print(f\"\\nâœ“ ××©×ª× ×” ×ª×œ×•×™ (y - Target):\")\n",
    "    print(f\"  - ×©×: Base Price (USD)\")\n",
    "    print(f\"  - ×¦×•×¨×”: {y.shape}\")\n",
    "    print(f\"  - ×˜×•×•×—: ${y.min():,.0f} - ${y.max():,.0f}\")\n",
    "    print(f\"  - ×××•×¦×¢: ${y.mean():,.0f}\")\n",
    "    \n",
    "    print(f\"\\nâœ“ ××©×ª× ×™× ×‘×œ×ª×™ ×ª×œ×•×™×™× (X - Features):\")\n",
    "    print(f\"  - ××¡×¤×¨ ××©×ª× ×™×: {X.shape[1]}\")\n",
    "    print(f\"  - ××¡×¤×¨ ×“×•×’×××•×ª: {X.shape[0]}\")\n",
    "    print(f\"  - ×¦×•×¨×”: {X.shape}\")\n",
    "    \n",
    "    print(f\"\\n  ×¨×©×™××ª ××©×ª× ×™×:\")\n",
    "    for i, col in enumerate(X.columns, 1):\n",
    "        print(f\"    {i:2}. {col}\")\n",
    "    \n",
    "    print(\"\\nâœ“ ×”×¤×¨×“×” ×”×•×©×œ××”!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ×¤×™×¦×•×œ Train-Test (80/20)\n",
    "\n",
    "**×œ××” ×œ×¤×¦×œ?**\n",
    "- **Train (80%)**: ×œ×œ××“ ××ª ×”××•×“×œ\n",
    "- **Test (20%)**: ×œ×‘×“×•×§ ××ª ×”××•×“×œ ×¢×œ × ×ª×•× ×™× ×©×”×•× ×œ× ×¨××”\n",
    "\n",
    "×–×” ××‘×˜×™×— ×©×”××•×“×œ ×‘×××ª ×œ××“ ×•×œ× ×¨×§ \"×©×™× ×Ÿ\"!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ×¤×™×¦×•×œ Train-Test\n",
    "print(\"=\"*80)\n",
    "print(\"×¤×™×¦×•×œ × ×ª×•× ×™×: Train-Test Split\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ“ ×¤×™×¦×•×œ ×”×•×©×œ×!\")\n",
    "print(f\"\\n× ×ª×•× ×™ ××™××•×Ÿ (Train):\")\n",
    "print(f\"  - X_train: {X_train.shape}\")\n",
    "print(f\"  - y_train: {y_train.shape}\")\n",
    "print(f\"  - ××—×•×–: {(len(X_train)/len(X))*100:.0f}%\")\n",
    "\n",
    "print(f\"\\n× ×ª×•× ×™ ×‘×“×™×§×” (Test):\")\n",
    "print(f\"  - X_test: {X_test.shape}\")\n",
    "print(f\"  - y_test: {y_test.shape}\")\n",
    "print(f\"  - ××—×•×–: {(len(X_test)/len(X))*100:.0f}%\")\n",
    "\n",
    "print(f\"\\n×¡×˜×˜×™×¡×˜×™×§×•×ª y:\")\n",
    "print(f\"  Train - ×××•×¦×¢: ${y_train.mean():,.0f}\")\n",
    "print(f\"  Test  - ×××•×¦×¢: ${y_test.mean():,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. × ×•×¨××œ×™×–×¦×™×” (Feature Scaling)\n",
    "\n",
    "**×œ××” ×¦×¨×™×š?**  \n",
    "××©×ª× ×™× ×‘×¡×§××œ×•×ª ×©×•× ×•×ª ×™×›×•×œ×™× ×œ×”×©×¤×™×¢ ×œ× × ×›×•×Ÿ ×¢×œ ×”××•×“×œ.\n",
    "\n",
    "**StandardScaler:**  \n",
    "×”×•×¤×š ×›×œ ××©×ª× ×” ×œ×××•×¦×¢ 0 ×•×¡×˜×™×™×ª ×ª×§×Ÿ 1\n",
    "\n",
    "**× ×•×¡×—×”:** `z = (x - Î¼) / Ïƒ`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# × ×•×¨××œ×™×–×¦×™×”\n",
    "print(\"=\"*80)\n",
    "print(\"× ×•×¨××œ×™×–×¦×™×” (Feature Scaling) - StandardScaler\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "print(\"\\nâœ“ × ×•×¨××œ×™×–×¦×™×” ×”×•×©×œ××”!\")\n",
    "\n",
    "print(f\"\\n×¡×˜×˜×™×¡×˜×™×§×•×ª ××—×¨×™ × ×•×¨××œ×™×–×¦×™×”:\")\n",
    "print(f\"  ×××•×¦×¢: {X_train_scaled.mean().mean():.6f} (×§×¨×•×‘ ×œ-0)\")\n",
    "print(f\"  ×¡×˜×™×™×ª ×ª×§×Ÿ: {X_train_scaled.std().mean():.6f} (×§×¨×•×‘ ×œ-1)\")\n",
    "\n",
    "print(f\"\\nâœ“ ×”× ×ª×•× ×™× ×× ×•×¨××œ×™× ×•××•×›× ×™× ×œ××•×“×œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ×©××™×¨×ª ×”× ×ª×•× ×™× ×”××¢×•×‘×“×™×"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ×©××™×¨×ª ×”× ×ª×•× ×™×\n",
    "print(\"=\"*80)\n",
    "print(\"×©××™×¨×ª × ×ª×•× ×™× ××¢×•×‘×“×™×\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "X_train_scaled.to_csv('X_train_scaled.csv', index=False)\n",
    "X_test_scaled.to_csv('X_test_scaled.csv', index=False)\n",
    "y_train.to_csv('y_train.csv', index=False, header=['Base Price (USD)'])\n",
    "y_test.to_csv('y_test.csv', index=False, header=['Base Price (USD)'])\n",
    "\n",
    "print(\"\\nâœ“ ×›×œ ×”×§×‘×¦×™× × ×©××¨×•:\")\n",
    "print(\"  - X_train_scaled.csv\")\n",
    "print(\"  - X_test_scaled.csv\")\n",
    "print(\"  - y_train.csv\")\n",
    "print(\"  - y_test.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ… ×¢×™×‘×•×“ ×”× ×ª×•× ×™× ×”×•×©×œ× ×‘×”×¦×œ×—×”!\")\n",
    "print(\"ğŸ“Œ ×”××©×š ×œ××—×‘×¨×ª ×”×‘××”: 3_model_building.ipynb\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“‹ ×¡×™×›×•× ×©×œ×‘ ×¢×™×‘×•×“ ×”× ×ª×•× ×™×\n",
    "\n",
    "âœ… **××” ×¢×©×™× ×•:**\n",
    "- ×‘×“×§× ×• ×¢×¨×›×™× ×—×¡×¨×™× (××™×Ÿ)\n",
    "- ×§×™×“×“× ×• ××©×ª× ×™× ×§×˜×’×•×¨×™××œ×™×™×\n",
    "- ×‘×—×¨× ×• ××©×ª× ×™× ×¨×œ×•×•× ×˜×™×™×\n",
    "- ×–×™×”×™× ×• outliers (×”×—×œ×˜× ×• ×œ×©××•×¨)\n",
    "- ×”×¤×¨×“× ×• X ×•-y\n",
    "- ×¤×™×¦×œ× ×• 80/20 Train-Test\n",
    "- ×‘×™×¦×¢× ×• × ×•×¨××œ×™×–×¦×™×”\n",
    "\n",
    "**×”× ×ª×•× ×™× ××•×›× ×™× ×œ×‘× ×™×™×ª ××•×“×œ! ğŸš€**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
